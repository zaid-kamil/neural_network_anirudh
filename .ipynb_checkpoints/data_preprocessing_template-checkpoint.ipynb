{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A template to solve any supervised ML classification problem.\n",
    "The flow:\n",
    "- Reading the data\n",
    "- Defining the problem statement\n",
    "- Identifying the Target variable\n",
    "- Looking at the distribution of Target variable\n",
    "- Basic Data exploration\n",
    "- Rejecting useless columns\n",
    "- Visual Exploratory Data Analysis for data distribution (Histogram and Barcharts)\n",
    "- Feature Selection based on data distribution\n",
    "- Outlier treatment\n",
    "- Missing Values treatment\n",
    "- Visual correlation analysis\n",
    "- Statistical correlation analysis (Feature Selection)\n",
    "- Selecting final predictors for Machine Learning\n",
    "- Saving the cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data\n",
    "This is one of the most important steps in machine learning! You must understand the data and the domain well before trying to apply any machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the distribution of Target variable\n",
    "- If target variable's distribution is too skewed then the predictive modeling will not be possible.\n",
    "- Bell curve is desirable but slightly positive skew or negative skew is also fine\n",
    "- When performing Classification, make sure there is a balance in the the distribution of each class otherwise it impacts the Machine Learning algorithms ability to learn all the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data exploration\n",
    "This step is performed to guage the overall data. The volume of data, the types of columns present in the data. Initial assessment of the data should be done to identify which columns are Quantitative, Categorical or Qualitative. This will help in further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rejecting useless columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Exploratory Data Analysis for data distribution (Histogram and Barcharts)\n",
    "- Categorical variables: Bar plot\n",
    "- Continuous variables: Histogram\n",
    "###  Visualize distribution of all the Categorical Predictor variables in the data using bar plots\n",
    "We can spot a categorical variable in the data by looking at the unique values in them. \n",
    "Typically a categorical variable contains less than 20 Unique values AND there is repetition of values, which means the data can be grouped by those unique values.\n",
    "\n",
    "### Bar Charts Interpretation\n",
    "In the ideal bar chart each category has comparable frequency. Hence, there are enough rows for each category in the data for the ML algorithm to learn.\n",
    "\n",
    "If there is a column which shows too skewed distribution where there is only one dominant bar and the other categories are present in very low numbers. These kind of columns may not be very helpful in machine learning. We confirm this in the correlation analysis section and take a final call to select or reject the column.\n",
    "\n",
    "### Histogram Interpretation\n",
    "Histograms shows us the data distribution for a single continuous variable.\n",
    "\n",
    "The X-axis shows the range of values and Y-axis represent the number of values in that range. For example, in the above histogram of \"Age\", there are around 175 rows in data that has a age between 20 to 30.\n",
    "\n",
    "The ideal outcome for histogram is a bell curve or slightly skewed bell curve. If there is too much skewness, then outlier treatment should be done and the column should be re-examined, if that also does not solve the problem then only reject the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier treatment\n",
    "Outliers are extreme values in the data which are far away from most of the values. You can see them as the tails in the histogram.\n",
    "\n",
    "Outlier must be treated one column at a time. As the treatment will be slightly different for each column.\n",
    "\n",
    "#### Why I should treat the outliers?\n",
    "\n",
    "Outliers bias the training of machine learning models. As the algorithm tries to fit the extreme value, it goes away from majority of the data.\n",
    "\n",
    "There are below two options to treat outliers in the data.\n",
    "\n",
    "- Option-1: Delete the outlier Records. Only if there are just few rows lost.\n",
    "- Option-2: Impute the outlier values with a logical business value\n",
    "\n",
    "#### Visualizing distribution after outlier treatment\n",
    "After outlier treatment, the distribution of the data should be checked again to see if the outlier treatment has worked or not.\n",
    "- If the distribution is still skewed then the outlier treatment has not worked and the column should be rejected.\n",
    "- If the distribution is now normal or slightly skewed then the outlier treatment has worked and the column can be considered for further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values treatment\n",
    "Missing values are treated for each column separately.\n",
    "\n",
    "If a column has more than 30% data missing, then missing value treatment cannot be done. That column must be rejected because too much information is missing.\n",
    "\n",
    "There are below options for treating missing values in data.\n",
    "\n",
    "- Delete the missing value rows if there are only few records\n",
    "- Impute the missing values with MEDIAN value for continuous variables\n",
    "- Impute the missing values with MODE value for categorical variables\n",
    "- Interpolate the values based on nearby values\n",
    "- Interpolate the values based on business logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection based on data distribution\n",
    "finally choose the best columns(Features) which are correlated to the Target variable. This can be done directly by measuring the correlation values or ANOVA/Chi-Square tests. However, it is always helpful to visualize the relation between the Target variable and each of the predictors to get a better sense of data.\n",
    "\n",
    "listed below the techniques used for visualizing relationship between two variables as well as measuring the strength statistically.\n",
    "\n",
    "### Visual exploration of relationship between variables\n",
    "- Continuous Vs Continuous ---- Scatter Plot\n",
    "- Categorical Vs Continuous---- Box Plot\n",
    "- Categorical Vs Categorical---- Grouped Bar Plots\n",
    "### Statistical measurement of relationship strength between variables\n",
    "- Continuous Vs Continuous ---- Correlation matrix\n",
    "- Categorical Vs Continuous---- ANOVA test\n",
    "- Categorical Vs Categorical--- Chi-Square test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship exploration: Categorical Vs Continuous -- Box Plots\n",
    "When the target variable is Categorical and the predictor variable is Continuous we analyze the relation using bar plots/Boxplots and measure the strength of relation using Anova test\n",
    "\n",
    "### Box-Plots interpretation\n",
    "What should you look for in these box plots?\n",
    "\n",
    "These plots gives an idea about the data distribution of continuous predictor in the Y-axis for each of the category in the X-Axis.\n",
    "\n",
    "If the distribution looks similar for each category(Boxes are in the same line), that means the the continuous variable has NO effect on the target variable. Hence, the variables are not correlated to each other.\n",
    "\n",
    "## Relationship exploration: Categorical Vs Categorical -- Grouped Bar Charts\n",
    "When the target variable is Categorical and the predictor is also Categorical then we explore the correlation between them visually using barplots and statistically using Chi-square test\n",
    "\n",
    "### Grouped Bar charts Interpretation\n",
    "What to look for in these grouped bar charts?\n",
    "\n",
    "These grouped bar charts show the frequency in the Y-Axis and the category in the X-Axis. If the ratio of bars is similar across all categories, then the two columns are not correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Feature Selection (Categorical Vs Continuous) using ANOVA test\n",
    "Analysis of variance(ANOVA) is performed to check if there is any relationship between the given continuous and categorical variable\n",
    "\n",
    "- Assumption(H0): There is NO relation between the given variables (i.e. The average(mean) values of the numeric Predictor variable is same for all the groups in the categorical Target variable)\n",
    "- ANOVA Test result: Probability of H0 being true\n",
    "\n",
    "## Statistical Feature Selection (Categorical Vs Categorical) using Chi-Square Test\n",
    "Chi-Square test is conducted to check the correlation between two categorical variables\n",
    "\n",
    "- Assumption(H0): The two columns are NOT related to each other\n",
    "- Result of Chi-Sq Test: The Probability of H0 being True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting final predictors for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
